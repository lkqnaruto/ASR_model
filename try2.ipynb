{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from typing import List, Dict, Set, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# Optional dependencies\n",
    "try:\n",
    "    from langdetect import detect, detect_langs\n",
    "    LANGDETECT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGDETECT_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    SPACY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SPACY_AVAILABLE = False\n",
    "\n",
    "class EnglishInSpanishDetector:\n",
    "    def __init__(self):\n",
    "        # Common English words that appear in Spanish conversations\n",
    "        self.common_english_words = {\n",
    "            # Technology and business terms\n",
    "            'computer', 'laptop', 'email', 'internet', 'website', 'online', 'app',\n",
    "            'smartphone', 'tablet', 'software', 'hardware', 'wifi', 'bluetooth',\n",
    "            'facebook', 'instagram', 'whatsapp', 'google', 'amazon', 'netflix',\n",
    "            \n",
    "            # Customer service terms\n",
    "            'customer service', 'manager', 'supervisor', 'representative', 'agent',\n",
    "            'account', 'balance', 'payment', 'credit', 'debit', 'transaction',\n",
    "            'statement', 'invoice', 'receipt', 'refund', 'discount', 'promotion',\n",
    "            \n",
    "            # Common expressions\n",
    "            'okay', 'ok', 'yes', 'no', 'please', 'thank you', 'thanks', 'sorry',\n",
    "            'excuse me', 'hello', 'hi', 'bye', 'goodbye', 'welcome', 'perfect',\n",
    "            \n",
    "            # Time and numbers\n",
    "            'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "            'january', 'february', 'march', 'april', 'may', 'june', 'july',\n",
    "            'august', 'september', 'october', 'november', 'december',\n",
    "            \n",
    "            # Locations and addresses\n",
    "            'street', 'avenue', 'boulevard', 'road', 'drive', 'lane', 'court',\n",
    "            'apartment', 'suite', 'floor', 'building', 'office', 'mall', 'center',\n",
    "            \n",
    "            # Common verbs and adjectives\n",
    "            'update', 'upgrade', 'download', 'upload', 'login', 'logout', 'reset',\n",
    "            'cancel', 'confirm', 'submit', 'apply', 'approve', 'reject', 'pending',\n",
    "            'available', 'unavailable', 'expired', 'valid', 'invalid', 'premium',\n",
    "            \n",
    "            # Measurements and quantities\n",
    "            'dollar', 'dollars', 'cent', 'cents', 'percent', 'percentage',\n",
    "            'gallon', 'gallons', 'mile', 'miles', 'inch', 'inches', 'foot', 'feet'\n",
    "        }\n",
    "        \n",
    "        # English function words (articles, prepositions, etc.)\n",
    "        self.english_function_words = {\n",
    "            'the', 'a', 'an', 'and', 'or', 'but', 'if', 'when', 'where', 'how',\n",
    "            'what', 'who', 'which', 'that', 'this', 'these', 'those', 'all',\n",
    "            'some', 'any', 'every', 'each', 'both', 'either', 'neither',\n",
    "            'in', 'on', 'at', 'by', 'for', 'with', 'without', 'to', 'from',\n",
    "            'up', 'down', 'over', 'under', 'above', 'below', 'between', 'among',\n",
    "            'I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "            'my', 'your', 'his', 'her', 'its', 'our', 'their', 'mine', 'yours', 'ours',\n",
    "            'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
    "            'do', 'does', 'did', 'will', 'would', 'can', 'could', 'should', 'must'\n",
    "        }\n",
    "        \n",
    "        # English patterns\n",
    "        self.english_patterns = [\n",
    "            r'\\b[a-z]+ing\\b',        # -ing endings (running, walking)\n",
    "            r'\\b[a-z]+ed\\b',         # -ed endings (worked, played)\n",
    "            r'\\b[a-z]+ly\\b',         # -ly adverbs (quickly, slowly)\n",
    "            r'\\b[a-z]+tion\\b',       # -tion endings (information, station)\n",
    "            r'\\b[a-z]+ness\\b',       # -ness endings (business, fitness)\n",
    "            r'\\bth[a-z]+\\b',         # words starting with 'th' (the, this, that)\n",
    "            r'\\b[a-z]*ough[a-z]*\\b', # words with 'ough' (through, tough)\n",
    "            r'\\b[a-z]*ph[a-z]*\\b',   # words with 'ph' (phone, graph)\n",
    "        ]\n",
    "        \n",
    "        # English names common in customer service\n",
    "        self.english_names = {\n",
    "            'john', 'james', 'robert', 'michael', 'william', 'david', 'richard',\n",
    "            'joseph', 'thomas', 'christopher', 'charles', 'daniel', 'matthew',\n",
    "            'anthony', 'donald', 'steven', 'paul', 'andrew', 'joshua', 'kenneth',\n",
    "            'mary', 'patricia', 'jennifer', 'linda', 'elizabeth', 'barbara',\n",
    "            'susan', 'jessica', 'sarah', 'karen', 'nancy', 'lisa', 'betty',\n",
    "            'helen', 'sandra', 'donna', 'carol', 'ruth', 'sharon', 'michelle',\n",
    "            'smith', 'johnson', 'williams', 'brown', 'jones', 'garcia', 'miller',\n",
    "            'davis', 'rodriguez', 'martinez', 'hernandez', 'lopez', 'gonzalez'\n",
    "        }\n",
    "        \n",
    "        # Speaker patterns (same as Spanish detector)\n",
    "        self.speaker_patterns = [\n",
    "            r'(Agent|Customer|Agente|Cliente):\\s*',\n",
    "            r'(A|C|AG|CU):\\s*',\n",
    "            r'\\[.*?\\]:\\s*',\n",
    "            r'\\d+:\\d+:\\d+\\s*-?\\s*'\n",
    "        ]\n",
    "        \n",
    "        # Initialize spaCy if available\n",
    "        self.nlp_en = None\n",
    "        self.nlp_es = None\n",
    "        self.spacy_available = False\n",
    "        \n",
    "        if SPACY_AVAILABLE:\n",
    "            try:\n",
    "                self.nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "                self.nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "                self.spacy_available = True\n",
    "            except OSError:\n",
    "                self.spacy_available = False\n",
    "    \n",
    "    def clean_transcript_text(self, text: str) -> str:\n",
    "        \"\"\"Clean transcript text by removing speaker indicators and timestamps\"\"\"\n",
    "        cleaned = text\n",
    "        \n",
    "        for pattern in self.speaker_patterns:\n",
    "            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
    "        \n",
    "        cleaned = re.sub(r'[\\[\\(]\\d{1,2}:\\d{2}:\\d{2}[\\]\\)]', '', cleaned)\n",
    "        cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def detect_english_words(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Detect English words using dictionary lookup\"\"\"\n",
    "        matches = []\n",
    "        words = re.finditer(r'\\b\\w+\\b', text)\n",
    "        \n",
    "        all_english_words = self.common_english_words | self.english_function_words\n",
    "        \n",
    "        for match in words:\n",
    "            word = match.group().lower()\n",
    "            if word in all_english_words:\n",
    "                start, end = match.span()\n",
    "                matches.append({\n",
    "                    'text': match.group(),\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'method': 'english_dictionary'\n",
    "                })\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def detect_english_patterns(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Detect English words using morphological patterns\"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        for pattern in self.english_patterns:\n",
    "            for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "                word = match.group()\n",
    "                start, end = match.span()\n",
    "                \n",
    "                # Filter out Spanish words that might match English patterns\n",
    "                if not self.looks_spanish(word.lower()):\n",
    "                    matches.append({\n",
    "                        'text': word,\n",
    "                        'start': start,\n",
    "                        'end': end,\n",
    "                        'method': 'english_pattern'\n",
    "                    })\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def looks_spanish(self, word: str) -> bool:\n",
    "        \"\"\"Check if a word looks Spanish (to avoid false positives)\"\"\"\n",
    "        # Spanish indicators\n",
    "        spanish_chars = {'ñ', 'á', 'é', 'í', 'ó', 'ú', 'ü'}\n",
    "        if any(char in word for char in spanish_chars):\n",
    "            return True\n",
    "        \n",
    "        # Common Spanish endings\n",
    "        spanish_endings = ['ción', 'sión', 'idad', 'mente', 'ando', 'iendo', 'ería']\n",
    "        if any(word.endswith(ending) for ending in spanish_endings):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def detect_english_names(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Detect English names\"\"\"\n",
    "        matches = []\n",
    "        words = re.finditer(r'\\b[A-Z][a-z]+\\b', text)\n",
    "        \n",
    "        for match in words:\n",
    "            word = match.group().lower()\n",
    "            if word in self.english_names:\n",
    "                start, end = match.span()\n",
    "                matches.append({\n",
    "                    'text': match.group(),\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'method': 'english_name'\n",
    "                })\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def detect_english_phrases(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Detect common English phrases\"\"\"\n",
    "        phrases = []\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        english_phrases = [\n",
    "            'thank you', 'excuse me', 'customer service', 'social security',\n",
    "            'credit card', 'bank account', 'phone number', 'zip code',\n",
    "            'how much', 'how many', 'what time', 'right now', 'of course',\n",
    "            'no problem', 'you\\'re welcome', 'have a good day', 'take care',\n",
    "            'let me know', 'make sure', 'find out', 'check out', 'sign up',\n",
    "            'log in', 'log out', 'call back', 'hang up', 'pick up'\n",
    "        ]\n",
    "        \n",
    "        for phrase in english_phrases:\n",
    "            pattern = r'\\b' + re.escape(phrase) + r'\\b'\n",
    "            for match in re.finditer(pattern, text_lower):\n",
    "                start, end = match.span()\n",
    "                original_phrase = text[start:end]\n",
    "                phrases.append({\n",
    "                    'text': original_phrase,\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'method': 'english_phrase'\n",
    "                })\n",
    "        \n",
    "        return phrases\n",
    "    \n",
    "    def detect_english_in_spanish_context(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Detect English words that appear in predominantly Spanish context\"\"\"\n",
    "        if not LANGDETECT_AVAILABLE:\n",
    "            return []\n",
    "        \n",
    "        results = []\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        current_pos = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if len(sentence) < 10:\n",
    "                current_pos += len(sentence) + 1\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Check if sentence is predominantly Spanish\n",
    "                detected_langs = detect_langs(sentence)\n",
    "                is_spanish_context = False\n",
    "                \n",
    "                for lang_info in detected_langs:\n",
    "                    if lang_info.lang == 'es' and lang_info.prob > 0.6:\n",
    "                        is_spanish_context = True\n",
    "                        break\n",
    "                \n",
    "                if is_spanish_context:\n",
    "                    # Find English words in this Spanish sentence\n",
    "                    words = re.finditer(r'\\b\\w+\\b', sentence)\n",
    "                    for word_match in words:\n",
    "                        word = word_match.group().lower()\n",
    "                        if (word in self.common_english_words or \n",
    "                            word in self.english_function_words):\n",
    "                            \n",
    "                            # Calculate position in original text\n",
    "                            sent_start = text.find(sentence, current_pos)\n",
    "                            if sent_start != -1:\n",
    "                                word_start = sent_start + word_match.start()\n",
    "                                word_end = sent_start + word_match.end()\n",
    "                                \n",
    "                                results.append({\n",
    "                                    'text': word_match.group(),\n",
    "                                    'start': word_start,\n",
    "                                    'end': word_end,\n",
    "                                    'method': 'english_in_spanish_context',\n",
    "                                    'spanish_sentence': sentence,\n",
    "                                    'confidence': lang_info.prob\n",
    "                                })\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            current_pos += len(sentence) + 1\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def spacy_english_detection(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Use spaCy to detect English linguistic features\"\"\"\n",
    "        if not self.spacy_available or not self.nlp_en:\n",
    "            return []\n",
    "        \n",
    "        english_features = []\n",
    "        \n",
    "        try:\n",
    "            doc = self.nlp_en(text)\n",
    "            \n",
    "            for token in doc:\n",
    "                # Skip punctuation and spaces\n",
    "                if not token.is_alpha:\n",
    "                    continue\n",
    "                \n",
    "                # English linguistic indicators\n",
    "                is_english = False\n",
    "                feature_type = None\n",
    "                \n",
    "                # English POS patterns\n",
    "                if token.pos_ in ['VERB'] and token.text.endswith(('ing', 'ed')):\n",
    "                    is_english = True\n",
    "                    feature_type = 'english_verb_form'\n",
    "                elif token.pos_ == 'ADV' and token.text.endswith('ly'):\n",
    "                    is_english = True\n",
    "                    feature_type = 'english_adverb'\n",
    "                elif token.pos_ == 'DET' and token.text.lower() in ['the', 'a', 'an']:\n",
    "                    is_english = True\n",
    "                    feature_type = 'english_article'\n",
    "                elif token.text.lower() in self.english_function_words:\n",
    "                    is_english = True\n",
    "                    feature_type = 'english_function_word'\n",
    "                \n",
    "                if is_english:\n",
    "                    english_features.append({\n",
    "                        'text': token.text,\n",
    "                        'start': token.idx,\n",
    "                        'end': token.idx + len(token.text),\n",
    "                        'method': 'spacy_english_linguistic',\n",
    "                        'feature_type': feature_type,\n",
    "                        'pos': token.pos_\n",
    "                    })\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return english_features\n",
    "    \n",
    "    def analyze_spanish_text(self, text: str) -> Dict:\n",
    "        \"\"\"Main method to analyze Spanish text for English content\"\"\"\n",
    "        cleaned_text = self.clean_transcript_text(text)\n",
    "        \n",
    "        results = {\n",
    "            'original_text': text,\n",
    "            'cleaned_text': cleaned_text,\n",
    "            'english_words': [],\n",
    "            'english_patterns': [],\n",
    "            'english_names': [],\n",
    "            'english_phrases': [],\n",
    "            'english_in_spanish_context': [],\n",
    "            'spacy_english_features': [],\n",
    "            'summary': defaultdict(int),\n",
    "            'spacy_status': self.spacy_available\n",
    "        }\n",
    "        \n",
    "        # Detect English words\n",
    "        english_words = self.detect_english_words(cleaned_text)\n",
    "        results['english_words'] = english_words\n",
    "        results['summary']['english_words'] = len(english_words)\n",
    "        \n",
    "        # Detect English patterns\n",
    "        english_patterns = self.detect_english_patterns(cleaned_text)\n",
    "        results['english_patterns'] = english_patterns\n",
    "        results['summary']['english_patterns'] = len(english_patterns)\n",
    "        \n",
    "        # Detect English names\n",
    "        english_names = self.detect_english_names(cleaned_text)\n",
    "        results['english_names'] = english_names\n",
    "        results['summary']['english_names'] = len(english_names)\n",
    "        \n",
    "        # Detect English phrases\n",
    "        english_phrases = self.detect_english_phrases(cleaned_text)\n",
    "        results['english_phrases'] = english_phrases\n",
    "        results['summary']['english_phrases'] = len(english_phrases)\n",
    "        \n",
    "        # Detect English in Spanish context\n",
    "        english_in_context = self.detect_english_in_spanish_context(cleaned_text)\n",
    "        results['english_in_spanish_context'] = english_in_context\n",
    "        results['summary']['english_in_spanish_context'] = len(english_in_context)\n",
    "        \n",
    "        # spaCy analysis\n",
    "        if self.spacy_available:\n",
    "            spacy_features = self.spacy_english_detection(cleaned_text)\n",
    "            results['spacy_english_features'] = spacy_features\n",
    "            results['summary']['spacy_english_features'] = len(spacy_features)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_english_content_summary(self, text: str) -> Dict:\n",
    "        \"\"\"Get summary of English content in Spanish text\"\"\"\n",
    "        analysis = self.analyze_spanish_text(text)\n",
    "        \n",
    "        # Collect all English content\n",
    "        all_english = []\n",
    "        \n",
    "        for category in ['english_words', 'english_patterns', 'english_names', \n",
    "                        'english_phrases', 'english_in_spanish_context']:\n",
    "            all_english.extend([item['text'] for item in analysis[category]])\n",
    "        \n",
    "        unique_english = list(set([item.lower() for item in all_english]))\n",
    "        \n",
    "        summary = {\n",
    "            'total_english_items': len(all_english),\n",
    "            'unique_english_items': len(unique_english),\n",
    "            'english_content': sorted(unique_english),\n",
    "            'code_switching_detected': len(analysis['english_in_spanish_context']) > 0,\n",
    "            'predominant_language': 'mixed' if len(all_english) > 10 else 'spanish',\n",
    "            'english_categories': {\n",
    "                'business_terms': any(word in unique_english \n",
    "                                    for word in ['account', 'payment', 'service', 'manager']),\n",
    "                'technology_terms': any(word in unique_english \n",
    "                                      for word in ['email', 'computer', 'online', 'app']),\n",
    "                'greetings': any(word in unique_english \n",
    "                               for word in ['hello', 'hi', 'thank you', 'thanks']),\n",
    "                'english_names': len(analysis['english_names']) > 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Example usage\n",
    "def test_english_in_spanish():\n",
    "    detector = EnglishInSpanishDetector()\n",
    "    \n",
    "    # Example Spanish texts with English mixed in\n",
    "    spanish_texts = [\n",
    "        # Technology context\n",
    "        \"Necesito ayuda con mi email. No puedo hacer login en la website.\",\n",
    "        \n",
    "        # Customer service context  \n",
    "        \"Hola, quiero hablar con el manager, por favor. Tengo problema con mi account.\",\n",
    "        \n",
    "        # Mixed conversation\n",
    "        \"Mi nombre es María García. I need help con mi credit card. Thank you.\",\n",
    "        \n",
    "        # Business context\n",
    "        \"Trabajo en marketing y uso mucho software para analytics. Es muy helpful.\",\n",
    "        \n",
    "        # Daily conversation\n",
    "        \"Voy al mall con mis friends. Después vamos a eat en el restaurant.\"\n",
    "    ]\n",
    "    \n",
    "    for i, text in enumerate(spanish_texts, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"SPANISH TEXT {i}:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Original: {text}\")\n",
    "        \n",
    "        # Analyze for English content\n",
    "        summary = detector.get_english_content_summary(text)\n",
    "        \n",
    "        print(f\"\\nENGLISH CONTENT SUMMARY:\")\n",
    "        print(f\"- Total English items: {summary['total_english_items']}\")\n",
    "        print(f\"- Unique English content: {summary['english_content']}\")\n",
    "        print(f\"- Code-switching detected: {summary['code_switching_detected']}\")\n",
    "        print(f\"- Contains business terms: {summary['english_categories']['business_terms']}\")\n",
    "        print(f\"- Contains technology terms: {summary['english_categories']['technology_terms']}\")\n",
    "        \n",
    "        # Get detailed analysis\n",
    "        analysis = detector.analyze_spanish_text(text)\n",
    "        \n",
    "        if analysis['english_phrases']:\n",
    "            print(f\"\\nENGLISH PHRASES FOUND:\")\n",
    "            for phrase in analysis['english_phrases']:\n",
    "                print(f\"  - '{phrase['text']}'\")\n",
    "        \n",
    "        if analysis['english_in_spanish_context']:\n",
    "            print(f\"\\nENGLISH IN SPANISH CONTEXT:\")\n",
    "            for item in analysis['english_in_spanish_context']:\n",
    "                print(f\"  - '{item['text']}' in: '{item['spanish_sentence']}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_english_in_spanish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
